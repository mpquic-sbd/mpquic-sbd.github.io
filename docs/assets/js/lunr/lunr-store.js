var store = [{
        "title": "Software Artifacts",
        "excerpt":"Learn how to install and run the experimental setup developed for our publications.     The software artifacts available here include:     A Vagrant VM installation   Automation scripts for video processing   Network scenario implementations   Source code:            MPQUIC-SBD implementation       AStream DASH player emulator       Caddy web server            Getting Started: Follow the instructions to install and run the experimental setup.  ","categories": [],
        "tags": [],
        "url": "/docs/artifacts/",
        "teaser": null
      },{
        "title": "Install the Experimental Setup",
        "excerpt":"Repository Structure   The MPQUIC-SBD repository contains the following source code structure:   1 2 3 4 5 6 7 8 9 10 11 12 mpquic-sbd/ ├── log/                         # Where log files with experimental results are placed ├── network/mininet/             # Network scenarios for the mininet emulator ├── /src                         # Application implementation |   └── AStream                  # AStream DASH player emulator (Python) |   └── caddy                    # Caddy Web Server (Golang) |   └── dash                     # Compiled files |   └── quic-go                  # MPQUIC (Golang) extended to support SBD ├── Caddyfile                    # Caddy web server configuration file ├── background_sbd.py            # Python script to generate background traffic (D-ITG) ├── build.sh                     # Shell script to build the application (/src) ├── tcp_core.py                  # Python script to generate background traffic (bulk)   All source code files are designed to run on 64-bit Linux hosts.     Install, build, and run from a Vagrant VM   Following Steps 1, 2, and 3 below provides an easy way to run MPQUIC-SBD.   Step 1: Requirements  First, install Vagrant and VirtualBox on your host system.   1 2 cd ~ sudo apt-get install -y vagrant virtualbox    Install Vagrant and VirtualBox using your package manager, as shown in the commands above. Just for reference, the versions we used were:     Vagrant 2.0.2+dfsg-2ubuntu8   VirtualBox 5.2.42-dfsg-0~ubuntu1.18.04.1     Step 2: Build the Vagrant VM  To clone our repository and build the VM, run the following commands:   1 2 3 4  cd ~  git clone https://github.com/mpquic-sbd/mpquic-sbd-vagrant.git  cd mpquic-sbd-vagrant  sh setup.sh   Warning: Do not run sh setup.sh again, as it will run vagrant up and overwrite the built Vagrant VM.   Building: Using the Vagrant configuration file (VBox/Vagrantfile) provided below, the VM will be provisioned with 4GB of RAM and a 2-core CPU, with Ubuntu 18.04 LTS (Bionic Beaver) inside, which you can adjust as needed. Software packages will be automatically installed via the VBox/install.sh script. This ensures that the build process correctly installs Go 1.12, MPQUIC-SBD, the AStream Video Streaming Emulator, the Caddy Web Server, and Mininet.   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ENV['VAGRANT_DEFAULT_PROVIDER'] = 'virtualbox'  Vagrant.configure(\"2\") do |config|   config.vm.box = \"ubuntu/bionic64\"   config.ssh.forward_agent = true   config.ssh.forward_x11 = true    config.vm.synced_folder \"../Workspace\", \"/home/vagrant/Workspace\"    config.vm.provider \"virtualbox\" do |vb|     # vb.gui = true     vb.memory = \"4096\"  # in MB     vb.cpus = \"2\"   end    config.vm.provision :shell, path: \"install.sh\", privileged: false end    After building, the experimental setup is located in the mpquic-sbd-vagrant/Workspace directory of your running VM and follows this structure:   1 2 3 ~/mpquic-sbd-vagrant ├── /Workspace |   ├── /mpquic-sbd   Warning: If you ran setup.sh in Step 2, you already built everything using ./build.sh, then your Vagrant VM is all set.    ","categories": [],
        "tags": [],
        "url": "/docs/installation/",
        "teaser": null
      },{
        "title": "Prepare the video files",
        "excerpt":"     DISCLAIMER:         We do not have any rights to the video content.     All video content must be selected from sources of your choice.     The MPQUIC-SBD repositories provide video scripts only for processing user-provided video content by encoding it and splitting it into segments of varying quality levels.        Notes:     Example of video source: Freely licensed video content can be found in public domain repositories such as Wikimedia.   Warning on video preparation: This is an offline process that may take a significant amount of time, depending on the video’s length and the desired quality. We recommend performing this process outside the Vagrant VM, e.g., directly on your host.   Information on reproducibility: In our experiments (refer to our publications), we use a 4K (3840 x 2160), 60 fps video file, 50 minutes in length, which is encoded in 11 different qualities and split into 2-, 4-, and 10-second segments.     Offline processing of video segments   Step 1: Requirements   First, install ffmpeg and GPAC’s MP4Box on your host system.   Run on your host:  1 sudo apt-get install -y ffmpeg gpac    Install ffmpeg and gpac using your package manager, as shown in the commands above. Just for reference, the versions we used were:     Ubuntu 18.04.6 LTS   gcc 6.5.0   MP4Box 0.5.2-426-gc5ad4e4+dfsg5-3ubuntu0.1   ffmpeg 7:3.4.11-0ubuntu0.1    Then, navigate to the mpquic-sbd-vagrant/Workspace folder and download our video processing scripts from our repository by running:   1 2 cd ~/mpquic-sbd-vagrant/Workspace git clone https://github.com/mpquic-sbd/video.git    Navigate to the mpquic-sbd-vagrant/Workspace/video folder, where you will find the following Python scripts:  1 2 3 4 5 ~/mpquic-sbd-vagrant/Workspace/video ├── video_download_process.py # downloads (wget) and processes (ffmpeg) a video file ├── video_sara_mpd.py         # creates an MPD file for the SARA ABR format ├── video_split.py            # splits the processed videos into the desired segment length (in seconds) ├── video_utils.py            # set of functions used to download, process, and split video files     Step 2: Download and process the video   The script video_download_process.py downloads and processes a video file (WEBM or MP4). Using ffmpeg, the original video is encoded into 11 different quality levels, as done in our experiments (refer to our publications).   In the mpquic-sbd-vagrant/Workspace/video folder, download and process the video by running:  1 2 cd ~/mpquic-sbd-vagrant/Workspace/video python3 video_download_process.py &lt;video file URL&gt;    For example, the Wikimedia’s video File:Walking in LONDON - England (UK) - Westminster to Piccadilly Circus (2019) - 4K 60fps (UHD).webm is a 4K, 60fps, 50+ minute video, which can be easily downloaded and processed as follows (note that this process may take several hours to complete):  1 2 cd ~/mpquic-sbd-vagrant/Workspace/video python3 video_download_process.py https://upload.wikimedia.org/wikipedia/commons/b/bf/Walking_in_LONDON_-_England_%28UK%29_-_Westminster_to_Piccadilly_Circus_%282019%29_-_4K_60fps_%28UHD%29.webm   The video_download_process.py script is expected to produce the following output files:  1 2 3 4 5 6 7 8 9 10 11 12 13 ~/mpquic-sbd-vagrant/Workspace/video ├── downloaded_video.webm   # original downloaded video file ├── video_21602p_60_fps.mp4 # q1:  processed video with 60 fps, 3840x2160   ├── video_2160p_30_fps.mp4  # q2:  processed video with 30 fps, 3840x2160  ├── video_14402p_60_fps.mp4 # q3:  processed video with 60 fps, 2560x1440 ├── video_1440p_30_fps.mp4  # q4:  processed video with 30 fps, 2560x1440 ├── video_10802p_60_fps.mp4 # q5:  processed video with 60 fps, 1920x1080 ├── video_1080p_25_fps.mp4  # q6:  processed video with 25 fps, 1920x1080  ├── video_7202p_60_fps.mp4  # q7:  processed video with 60 fps, 1280x720    ├── video_720p_25_fps.mp4   # q8:  processed video with 25 fps, 1280x720   ├── video_480p_25_fps.mp4   # q9:  processed video with 25 fps, 854x480 ├── video_360p_25_fps.mp4   # q10: processed video with 25 fps, 640x360 ├── video_240p_25_fps.mp4   # q11: processed video with 25 fps, 426x240   Warning: do not change the file names, as it causes the other scripts to fail.    Step 3: Split the processed video into segments   The script video_split.py uses MP4Box to split the entire video file into chunks, i.e., segments in sequence, each containing a few seconds of the video. In our experiments (refer to our publications), we split the video into 2-, 4-, and 10-second segments. To do this, run the following commands:  1 2 3 4 cd ~/mpquic-sbd-vagrant/Workspace/video python3  video_split.py  2 python3  video_split.py  4 python3  video_split.py  10   In addition to the original downloaded video (downloaded_video.webm) and the processed videos in 11 different qualities (video_*.mp4), the video_split.py script is expected to produce the following outputs:  1 2 3 4 5 6 7 8 9 mpquic-sbd-vagrant/Workspace/video ├── 2s                    # folder for 2-second segments |   └── output_dash.mpd   # MPD manifest file describing all 2-second video segments and qualities |   └── output_dash2.mpd  # MPD manifest file adapted for the SARA ABR algorithm |   └── segment_*.m4s     # A number of video files containing 2-seconds segments ├── 4s                    # folder for 4-second segments |   └── ...               # MPD files and segments as in the 2s folder ├── 10s                   # folder for 10-second segments |   └── ...               # MPD files and segments as in the 2s folder   Warning: do not change the file names, as it causes the video streaming application to fail.    Step 4: Check the location of the video files   The ~/mpquic-sbd-vagrant/Workspace folder is shared between your host and the Vagrant VM. Ensure that the MPQUIC-SBD experimental setup and the video files are placed in this folder. Inside your ~/mpquic-sbd-vagrant/Workspace, you should see two folders:  1 2 3 4 mpquic-sbd-vagrant ├── Workspace/ |   ├── mpquic-sbd/   # source files of the experimental setup |   ├── video/        # the folder storing the video files     ","categories": [],
        "tags": [],
        "url": "/docs/video/",
        "teaser": null
      },{
        "title": "Configure the video application",
        "excerpt":"Step 1: Configure Caddy web server   For DASH video streaming, we use the Caddy web server. It requires a configuration to serve the video segments from a file named Caddyfile.   The following Caddyfile is configured for 4-second video files in our network scenarios (refer to our publications) and is located at ~/mpquic-sbd-vagrant/Workspace/mpquic-sbd/Caddyfile.   1 2 3 4 5 6 7 8 9 10 11 12 # Unsecure listener for debugging purposes http://10.0.2.2:4040 {     root /home/vagrant/Workspace/video/4s     log stdout }  # Secure listener, required for TLS and QUIC connections https://10.0.2.2:4242 {     root /home/vagrant/Workspace/video/4s     tls self_signed     log stdout }    Notes:     The path to the video files in line 3 and 9 should reflect the path inside the Vagrant VM, i.e., /home/vagrant/Workspace/mpquic-sbd/Caddyfile.   The Vagrant VM’s /home/vagrant/Workspace folder is mapped to your host at ~/mpquic-sbd-vagrant/Workspace/.   To run the Caddy web server with different video segments, just modify lines 3 and 9 to point to the correct subfolder, e.g., /home/vagrant/Workspace/video/2s for 2-second segments, or /home/vagrant/Workspace/video/10s for 10-second segments.      Step 2: Configure the Adaptive Birate (ABR) algorithms in the AStream client player   Navigate to the AStream implementation folder:”  1 cd ~/mpquic-sbd-vagrant/Workspace/mpquic-sbd/src/AStream/dist/client/   Next, in the config_dash.py file you can set the ABR parameters after line 52.  # Constants for the BASIC-2 adaptation scheme BASIC_THRESHOLD = 1 BASIC_UPPER_THRESHOLD = 1.5 # Additional constant for the BASIC-3 adaptation scheme BASIC_LOWER_THRESHOLD = 0.9 # Number of segments for moving average BASIC_DELTA_COUNT = 20  # --------------------------------------------------- # SARA (Segment Aware Rate Adaptation) # --------------------------------------------------- # Number of segments for moving weighted average SARA_SAMPLE_COUNT = 5 # Constants for the Buffer in the Weighted adaptation scheme (in segments) INITIAL_BUFFERING_COUNT = 1 RE_BUFFERING_COUNT = 1 ALPHA_BUFFER_COUNT = 1 BETA_BUFFER_COUNT = 2 # Set the size of the buffer in terms of segments. Set to unlimited if 0 or None MAX_BUFFER_SIZE = 1  # --------------------------------------------------- # Netflix (Buffer-based) ADAPTATION # --------------------------------------------------- # Constants for the Netflix Buffering scheme adaptation/netflix_buffer.py # Constants is terms of buffer occupancy PERCENTAGE(%) NETFLIX_RESERVOIR = 0.1 NETFLIX_CUSHION = 0.9 # Buffer Size in Number of segments 240/4 NETFLIX_BUFFER_SIZE = 60 NETFLIX_INITIAL_BUFFER = 2 NETFLIX_INITIAL_FACTOR = 0.875 # ...    Buffer size is determined by the number of segments based on the total video duration. Specifically:     The TBA (basic) ABR, by default, has a minimal buffer size (i.e., only 1 video segment), which results in a significant number of stall events during video playback.   The Hybrid (SARA) ABR uses the numbers of segments defined in ALPHA_BUFFER_COUNT and BETA_BUFFER_COUNT as thresholds to manage the buffer.   The BBA (Netflix) ABR buffer size is configured using the NETFLIX_BUFFER_SIZE parameter. In the example above, the buffer size is set to NETFLIX_BUFFER_SIZE = 60, assuming a total video duration of 240 minutes and a segment length of 4 seconds. Adjust NETFLIX_BUFFER_SIZE to reflect the total video duration in your experiments.   ","categories": [],
        "tags": [],
        "url": "/docs/video-application/",
        "teaser": null
      },{
        "title": "Run the experiments",
        "excerpt":"Network scenarios on the Mininet emulator   In our experiments (refer to our publications), we focus on network scenarios where a multi-homed client (AStream DASH player) is connected to two access networks, while at the other end, the video server (Caddy web server) is connected to a single access network. This setup results in an MPQUIC session with two paths between the DASH client and the video server.    Note:  We implemented three network scenarios using the Mininet emulator (Python scripts are available on your host in ~/mpquic-sbd-vagrant/Workspace/mpquic-sbd/network/mininet/). In these scenarios, the paths between the client and server are configured as follows:     &lt;1&gt;: NSB (Non-Shared Bottlenecks): Each path traverses a distinct bottleneck link, meaning they do not share network resources.   &lt;2&gt;: SB (Shared Bottleneck): Both paths flow through the same bottleneck link, sharing the same network resource.   &lt;3&gt;: SHIFT (Shifting SB-NSB): The bottlenecks alternate between SB and NSB every 40 seconds during the MPQUIC session.     Run the Vagrant VM   On your host, navigate to the ~/mpquic-sbd-vagrant/VBox folder, reload the virtual machine, and connect to it.  1 2 3  cd ~/mpquic-sbd-vagrant/VBox  vagrant reload  vagrant ssh    Run the MPQUIC-SBD experiments   To run our experiments with MPQUIC-SBD on Mininet emulator:  1 2 cd ~/Workspace/mpquic-sbd/ sudo python network/mininet/build_mininet_router&lt;scenario&gt;.py -nm 2 -p '&lt;ABR&gt;'  Where:     &lt;scenario&gt;: Specifies the number of the desired experiment. Enter 1 for NSB, 2 for SB, or 3 for SHIFT.   -nm: Indicates the number of network interface controllers for the client. Unless you have modified the network scenarios, always enter 2, as the client is dual-homed in our experiments.   -p: Specifies the ABR (Adaptive Bitrate) algorithm to use with the client DASH player (AStream). The available ABR algorithm implementations in AStream are: 'basic', a throughput-based algorithm (TBA); 'netflix', a buffer-based algorithm (BBA); and 'sara', a hybrid TBA/BBA algorithm.   For example, for you to run an experiment considering NSB scenario and the BBA ABR:  1 2 cd ~/Workspace/mpquic-sbd/ sudo python network/mininet/build_mininet_router1.py -nm 2 -p 'netflix'       What happens: When running the build_mininet_router*.py scripts, you will first see command-line output from the mininet emulator as it creates the network topology. Then, the terminal prompt remains be blocked while mininet starts and runs the application processes (e.g., D-ITG background traffic, the caddy web server, and the AStream player). Once these processes are completed and the experiment is finished, the prompt (mininet&gt; ) will return. At this point, you can exit mininet by typing exit.   Monitor the log output files: Since the ~/mpquic-sbd-vagrant/Workspace/ folder on your host is mapped to the /home/vagrant/Workspace folder in the Vagrant VM, you can monitor the experiment’s output files in real-time while the Vagrant terminal is blocked with mininet. To do this, open another terminal on your host and navigate to the folder containing the output logs:     1 2 cd ~/mpquic-sbd-vagrant/Workspace/mpquic-sbd/log/ tail -f &lt;log file&gt;           ","categories": [],
        "tags": [],
        "url": "/docs/run-experiments/",
        "teaser": null
      },{
        "title": "Verify the experimental results",
        "excerpt":"Warning: AStream emulates a DASH video player, so you will not see a video playback window during the experiments. Additionally, in our experiments (network scenarios in network/mininet/), we run AStream with the option to delete video segment files after playback.   The experimental results must be processed from the output files generated in the ~/Workspace/mpquic-sbd/log folder:      ASTREAM_&lt;DATE&gt;.json: This file contains results processed by AStream. It includes details about video segments for each downloaded segment, transport protocol information, playback data, and video metadata.   DASH_BUFFER_LOG_&lt;DATE&gt;.csv: This file logs events related to AStream buffer management. For each event, it provides the following details: epoch time, current playback time, current buffer size, playback state, action, and bitrate.   itg-*-&lt;DATE&gt;: Binary files generated by D-ITG for background traffic.   output_&lt;ABR&gt;_&lt;DATE&gt;.txt: A log file that records all events during AStream execution. It includes timestamps, corresponding code lines, log types, and textual descriptions of events. This log file must be parsed to extract results, e.g., throughput, latency, SBD accuracy, etc.    ","categories": [],
        "tags": [],
        "url": "/docs/results/",
        "teaser": null
      },]
